# transformer-time-series

In this research, two "Transformer" architectures will be used, namely the "Transformer" Encoder-Decoder architecture and the "Transformer" FC layer which only uses the encoder part. In this study, several different hyperparameters will be tested, using different numbers of heads for about 8 and 16 and experiments with different layer hyperparameters. 
